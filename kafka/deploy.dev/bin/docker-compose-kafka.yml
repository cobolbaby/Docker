version: "3.4"
services:

  broker1:
    image: ${REGISTRY}/hub/confluentinc/cp-kafka:5.4.2
    hostname: broker1
    ports:
      - target: 9092
        published: 9092
        protocol: tcp
        mode: host
      - target: 9990
        published: 9990
        protocol: tcp
        mode: host
      - target: 9999
        published: 9999
        protocol: tcp
        mode: host
    volumes:
      - /disk/kafka:/kafka
      - /opt/kafka/jmx_exporter:/opt/kafka/jmx_exporter
      - /etc/localtime:/etc/localtime:ro
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LOG_DIRS: /kafka/kafka-logs-broker1
      KAFKA_ZOOKEEPER_CONNECT: ${ZOOKEEPER}
      KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS: 6000
      KAFKA_LISTENERS: PLAINTEXT://:9092
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${BROKER_NODE1_IP}:9092
      KAFKA_LOG_CLEANUP_POLICY: delete,compact
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 21474836480
      # 墓碑消息存留时间
      KAFKA_LOG_CLEANER_DELETE_RETENTION_MS: 86400000
      KAFKA_MESSAGE_MAX_BYTES: 10485760
      KAFKA_REPLICA_FETCH_MAX_BYTES: 10485760
      # 不允许自动创建Topic，需要手动创建
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      # 用于端到端测试
      # KAFKA_LOG_MESSAGE_TIMESTAMP_TYPE: LogAppendTime
      KAFKA_HEAP_OPTS: "-Xmx2g -Xms2g"
      KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
      KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
      # KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_JMX_HOSTNAME: ${BROKER_NODE1_IP}
      KAFKA_JMX_PORT: 9999
      KAFKA_OPTS: "-javaagent:/opt/kafka/jmx_exporter/jmx_prometheus_javaagent-0.11.0.jar=9990:/opt/kafka/jmx_exporter/kafka-agent.yml"
      KAFKA_NUM_RECOVERY_THREADS_PER_DATA_DIR: 2
      KAFKA_INTER_BROKER_PROTOCOL_VERSION: "2.4"
      KAFKA_LOG_MESSAGE_FORMAT_VERSION: "2.0"
    deploy:
      restart_policy:
        condition: on-failure
        delay: 10s
      placement:
        constraints:
          - node.labels.alias == bdc01.infra.dev.tj.itc.inventec
      resources:
        limits:
          cpus: "2"
          memory: 4g

  broker2:
    image: ${REGISTRY}/hub/confluentinc/cp-kafka:5.4.2
    hostname: broker2
    ports:
      - target: 9092
        published: 9092
        protocol: tcp
        mode: host
      - target: 9990
        published: 9990
        protocol: tcp
        mode: host
      - target: 9999
        published: 9999
        protocol: tcp
        mode: host
    volumes:
      - /disk/kafka:/kafka
      - /opt/kafka/jmx_exporter:/opt/kafka/jmx_exporter
      - /etc/localtime:/etc/localtime:ro
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_LOG_DIRS: /kafka/kafka-logs-broker2
      KAFKA_ZOOKEEPER_CONNECT: ${ZOOKEEPER}
      KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS: 6000
      KAFKA_LISTENERS: PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${BROKER_NODE2_IP}:9092
      KAFKA_LOG_CLEANUP_POLICY: delete,compact
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 21474836480
      KAFKA_LOG_CLEANER_DELETE_RETENTION_MS: 86400000
      KAFKA_MESSAGE_MAX_BYTES: 10485760
      KAFKA_REPLICA_FETCH_MAX_BYTES: 10485760
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      # KAFKA_LOG_MESSAGE_TIMESTAMP_TYPE: LogAppendTime
      KAFKA_HEAP_OPTS: "-Xmx2g -Xms2g"
      KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
      KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
      # KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_JMX_HOSTNAME: ${BROKER_NODE2_IP}
      KAFKA_JMX_PORT: 9999
      KAFKA_OPTS: "-javaagent:/opt/kafka/jmx_exporter/jmx_prometheus_javaagent-0.11.0.jar=9990:/opt/kafka/jmx_exporter/kafka-agent.yml"
      KAFKA_NUM_RECOVERY_THREADS_PER_DATA_DIR: 2
      KAFKA_INTER_BROKER_PROTOCOL_VERSION: "2.4"
      KAFKA_LOG_MESSAGE_FORMAT_VERSION: "2.0"
    deploy:
      restart_policy:
        condition: on-failure
        delay: 10s
      placement:
        constraints:
          - node.labels.alias == bdc03.infra.dev.tj.itc.inventec
      resources:
        limits:
          cpus: "2"
          memory: 4g

  broker3:
    image: ${REGISTRY}/hub/confluentinc/cp-kafka:5.4.2
    hostname: broker3
    ports:
      - target: 9092
        published: 9092
        protocol: tcp
        mode: host
      - target: 9990
        published: 9990
        protocol: tcp
        mode: host
      - target: 9999
        published: 9999
        protocol: tcp
        mode: host
    volumes:
      - /disk/kafka:/kafka
      - /opt/kafka/jmx_exporter:/opt/kafka/jmx_exporter
      - /etc/localtime:/etc/localtime:ro
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_LOG_DIRS: /kafka/kafka-logs-broker3
      KAFKA_ZOOKEEPER_CONNECT: ${ZOOKEEPER}
      KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS: 6000
      KAFKA_LISTENERS: PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${BROKER_NODE3_IP}:9092
      KAFKA_LOG_CLEANUP_POLICY: delete,compact
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 21474836480
      KAFKA_LOG_CLEANER_DELETE_RETENTION_MS: 86400000
      KAFKA_MESSAGE_MAX_BYTES: 10485760
      KAFKA_REPLICA_FETCH_MAX_BYTES: 10485760
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      # KAFKA_LOG_MESSAGE_TIMESTAMP_TYPE: LogAppendTime
      KAFKA_HEAP_OPTS: "-Xmx2g -Xms2g"
      KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
      KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
      # KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_JMX_HOSTNAME: ${BROKER_NODE3_IP}
      KAFKA_JMX_PORT: 9999
      KAFKA_OPTS: "-javaagent:/opt/kafka/jmx_exporter/jmx_prometheus_javaagent-0.11.0.jar=9990:/opt/kafka/jmx_exporter/kafka-agent.yml"
      KAFKA_NUM_RECOVERY_THREADS_PER_DATA_DIR: 2
      KAFKA_INTER_BROKER_PROTOCOL_VERSION: "2.4"
      KAFKA_LOG_MESSAGE_FORMAT_VERSION: "2.0"
    deploy:
      restart_policy:
        condition: on-failure
        delay: 10s
      placement:
        constraints:
          - node.labels.alias == bdc04.infra.dev.tj.itc.inventec
      resources:
        limits:
          cpus: "2"
          memory: 4g

  kafka-connect:
    image: ${REGISTRY}/development/cp-kafka-connect:5.3.3-p1
    hostname: kafka-connect
    ports:
      - "8083:8083"
    volumes:
      - /etc/localtime:/etc/localtime:ro
    environment:
      CONNECT_BOOTSTRAP_SERVERS: broker1:9092,broker2:9092,broker3:9092
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_REST_PORT: 8083
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/kafka/plugins
      CONNECT_GROUP_ID: kafka-sink-connect
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      # CONNECT_LOG4J_LOGGERS: "io.debezium.connector.sqlserver=TRACE,io.debezium.jdbc=TRACE"
    deploy:
      restart_policy:
        condition: on-failure
        delay: 10s
      resources:
        limits:
          cpus: "2"
          memory: 4g

  # kafka-schema-registry:
  #   image: ${REGISTRY}/hub/confluentinc/cp-schema-registry:${BROKER_VERSION}
  #   hostname: kafka-schema-registry
  #   ports:
  #     - "8081:8081"
  #   environment:
  #     SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
  #     SCHEMA_REGISTRY_HOST_NAME: kafka-schema-registry
  #     SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: ${ZOOKEEPER}
  #     SCHEMA_REGISTRY_DEBUG: "true"
  #   deploy:
  #     restart_policy:
  #       condition: on-failure
  #     resources:
  #       limits:
  #         cpus: "1"
  #         memory: 1g

networks:
  default:
    external:
      name: bdc
